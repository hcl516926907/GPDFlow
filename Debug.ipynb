{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80409765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pgrad2/2448355h/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import normflows as nf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "276d19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 64\n",
    "torch.manual_seed(0)\n",
    "\n",
    "latent_size = 3\n",
    "b = torch.Tensor([1 if i % 2 == 0 else 0 for i in range(latent_size)])\n",
    "flows = []\n",
    "for i in range(K):\n",
    "    s = nf.nets.MLP([latent_size, 2 * latent_size, latent_size], init_zeros=True)\n",
    "    t = nf.nets.MLP([latent_size, 2 * latent_size, latent_size], init_zeros=True)\n",
    "    if i % 2 == 0:\n",
    "        flows += [nf.flows.MaskedAffineFlow(b, t, s)]\n",
    "    else:\n",
    "        flows += [nf.flows.MaskedAffineFlow(1 - b, t, s)]\n",
    "    flows += [nf.flows.ActNorm(latent_size)]\n",
    "\n",
    "# Set target and q0\n",
    "target = nf.distributions.TwoModes(2, 0.1)\n",
    "q0 = nf.distributions.DiagGaussian(3)\n",
    "\n",
    "# Construct flow model\n",
    "nfm = nf.NormalizingFlow(q0=q0, flows=flows, p=target)\n",
    "\n",
    "# Move model on GPU if available\n",
    "enable_cuda = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n",
    "nfm = nfm.to(device)\n",
    "nfm = nfm.double()\n",
    "\n",
    "# # Initialize ActNorm\n",
    "# z, _ = nfm.sample(num_samples=2 ** 7)\n",
    "# z_np = z.to('cpu').data.numpy()\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.hist2d(z_np[:, 0].flatten(), z_np[:, 1].flatten(), (200, 200), range=[[-3, 3], [-3, 3]])\n",
    "# plt.gca().set_aspect('equal', 'box')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5a32e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.flows.ActNorm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e483024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2310, -0.2466,  0.2542],\n",
       "         [-2.2561,  0.2985,  0.6747],\n",
       "         [ 0.0110,  0.7697, -0.1960],\n",
       "         [-0.3830,  0.3615,  1.4689],\n",
       "         [-1.8308, -0.2434,  1.4231],\n",
       "         [ 1.4952, -1.3010,  0.0448],\n",
       "         [-1.4006, -1.5375,  0.8261],\n",
       "         [-0.2512, -0.9926, -0.4794],\n",
       "         [ 3.3470, -0.1726, -1.6598],\n",
       "         [ 1.4229, -0.6594, -0.7005],\n",
       "         [-1.3513, -0.3014, -0.1973],\n",
       "         [-0.5242, -0.2385,  0.1218],\n",
       "         [-0.6400, -0.1468,  1.4666],\n",
       "         [-1.8371,  0.5541, -0.6326],\n",
       "         [ 1.2369,  1.1436,  0.2803],\n",
       "         [ 0.1570, -0.6331,  0.2227],\n",
       "         [-0.1866, -1.0101,  0.7032],\n",
       "         [-1.0066,  0.8973,  0.3347],\n",
       "         [-0.2482, -1.0921,  0.6724],\n",
       "         [-0.1055, -0.8088, -1.0538],\n",
       "         [-1.4080, -1.0828, -1.4317],\n",
       "         [ 0.0810, -0.0929,  0.9800],\n",
       "         [-0.6054,  0.6620,  0.5119],\n",
       "         [ 0.2031,  1.7305,  0.3904],\n",
       "         [ 0.4066, -1.2152, -1.4456],\n",
       "         [-0.8567, -1.2097, -0.0196],\n",
       "         [ 1.1257,  0.5968,  0.2845],\n",
       "         [ 1.4980, -1.0042,  1.2530],\n",
       "         [ 1.2503,  1.6014, -0.4699],\n",
       "         [-0.9220,  1.7561,  0.9581],\n",
       "         [ 1.1604,  0.9525, -2.7304],\n",
       "         [-2.0975,  1.6849,  0.0978],\n",
       "         [-0.0969,  0.3842, -0.6639],\n",
       "         [-0.3853, -0.0552, -0.1088],\n",
       "         [ 1.5444,  1.0355,  1.0384],\n",
       "         [-1.9436, -0.4210, -0.7193],\n",
       "         [-0.0360,  0.7548,  0.3556],\n",
       "         [ 0.0681,  0.2123, -1.1584],\n",
       "         [ 0.3755,  0.5198,  1.1822],\n",
       "         [-0.6498, -1.7563, -2.5442],\n",
       "         [ 1.1759, -0.9218,  1.3077],\n",
       "         [-0.1703,  0.5333,  0.1228],\n",
       "         [-0.5629, -0.0825,  0.6143],\n",
       "         [-0.0784,  0.8223,  1.0584],\n",
       "         [ 0.6195, -1.3828, -0.3838],\n",
       "         [ 0.1382, -0.8728,  0.5958],\n",
       "         [-0.0572,  0.1117,  1.9227],\n",
       "         [ 0.1748,  0.8066,  0.5357],\n",
       "         [ 0.5730,  1.6159, -1.3915],\n",
       "         [ 0.6791,  0.3867, -0.3094],\n",
       "         [ 0.3144,  1.4758,  0.1181],\n",
       "         [ 0.6002, -0.2406, -0.0206],\n",
       "         [-1.2728, -2.0586,  1.5722],\n",
       "         [-0.4941, -1.5272, -0.2563],\n",
       "         [ 0.2195,  1.7546,  1.3782],\n",
       "         [ 0.9077,  0.5096,  1.4662],\n",
       "         [ 0.1179,  0.9726,  0.8601],\n",
       "         [-0.9460, -0.3917,  0.2156],\n",
       "         [ 0.4220,  0.4160, -1.9485],\n",
       "         [-0.8400, -1.5129,  0.8968],\n",
       "         [-0.1243, -0.6065, -0.1875],\n",
       "         [-1.4317, -0.4802,  1.3485],\n",
       "         [-0.9758, -0.3544, -2.5918],\n",
       "         [-2.0743,  0.3276, -0.7377],\n",
       "         [ 0.3816, -0.7642,  0.8073],\n",
       "         [ 0.1097,  0.4387,  1.1031],\n",
       "         [ 0.9994, -0.5704,  0.2801],\n",
       "         [-0.0319, -1.1473,  0.0390],\n",
       "         [ 0.3796,  0.1637,  0.4395],\n",
       "         [ 0.8470,  0.9931,  1.5777],\n",
       "         [-0.5659, -1.6948, -0.1738],\n",
       "         [ 1.3633,  0.5915, -0.4518],\n",
       "         [ 0.4256,  1.4951,  0.6966],\n",
       "         [ 0.9034,  1.9367,  0.1988],\n",
       "         [ 0.0837,  0.9022,  0.4894],\n",
       "         [ 0.4968,  0.0474, -1.3806],\n",
       "         [-0.5144, -0.2106, -2.3828],\n",
       "         [ 1.2264,  0.5066, -0.8369],\n",
       "         [-1.6990,  0.7634,  1.1779],\n",
       "         [-0.9862,  0.7964,  0.0692],\n",
       "         [ 0.1677,  0.4557,  1.2326],\n",
       "         [ 0.3789,  1.3441, -0.7935],\n",
       "         [-0.1086, -0.8964, -0.9255],\n",
       "         [-0.0743, -0.5523, -0.4206],\n",
       "         [ 1.0866, -1.5136,  1.5264],\n",
       "         [ 0.7463, -0.1149, -0.8087],\n",
       "         [-0.1221, -0.1456, -0.2977],\n",
       "         [ 0.3038, -1.4224,  1.0527],\n",
       "         [-0.0727,  0.0991, -3.0618],\n",
       "         [ 1.4361,  1.5251, -0.1677],\n",
       "         [-0.9490, -0.4113, -0.7520],\n",
       "         [-0.5817, -0.0748,  0.7463],\n",
       "         [-0.5551,  0.2871, -0.3792],\n",
       "         [ 0.5971,  0.2342, -0.0652],\n",
       "         [ 0.1116, -1.2834,  0.9205],\n",
       "         [ 1.7256, -0.8215,  0.1329],\n",
       "         [-0.9711,  0.4081, -0.2407],\n",
       "         [-0.4230,  0.7604,  0.4756],\n",
       "         [ 0.0118, -0.2438,  0.7621],\n",
       "         [ 0.3179,  1.1668,  0.2880],\n",
       "         [-0.4607, -0.1956,  0.1763],\n",
       "         [ 0.8949, -1.1640, -0.5781],\n",
       "         [ 1.1727, -0.4916,  0.2238],\n",
       "         [ 0.5459,  0.5470, -1.1531],\n",
       "         [ 0.8200, -0.6882, -0.9233],\n",
       "         [ 0.1469,  3.0802,  1.9230],\n",
       "         [ 0.4289, -0.4022, -1.7521],\n",
       "         [ 0.6456,  0.7488,  0.0707],\n",
       "         [ 0.1961,  0.0059, -1.0126],\n",
       "         [-1.5394, -1.5053, -0.2986],\n",
       "         [ 1.9778,  0.8840, -0.6229],\n",
       "         [-0.2080, -1.0538,  0.7128],\n",
       "         [ 0.7578, -0.5060, -0.1735],\n",
       "         [-1.8770, -0.5692,  0.0571],\n",
       "         [ 1.9902, -0.3275, -0.9444],\n",
       "         [-0.9695, -0.0683,  0.8343],\n",
       "         [-1.4629, -1.1414, -0.3559],\n",
       "         [ 0.4756, -1.2121, -1.6208],\n",
       "         [ 1.0557, -0.9122,  0.5319],\n",
       "         [-0.7132, -0.5802,  0.3849],\n",
       "         [-0.0747,  2.3966,  0.1991],\n",
       "         [-1.0527,  0.3175, -0.5352],\n",
       "         [-1.7016, -0.4070, -0.3228],\n",
       "         [-1.5687, -0.2518, -1.3540],\n",
       "         [ 0.9478,  1.8814,  0.9506],\n",
       "         [ 0.1199,  0.8275, -0.7303],\n",
       "         [ 0.1914,  0.8715,  0.2316],\n",
       "         [ 1.7715, -2.1270, -0.3155]], device='cuda:0', dtype=torch.float64,\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([-2.9519, -5.7713, -3.3878, -3.9786, -5.4033, -4.4029, -5.0364, -3.3616,\n",
       "         -9.1504, -4.0709, -3.9000, -3.0669, -3.9636, -5.1285, -4.4274, -2.9872,\n",
       "         -3.4055, -4.0852, -3.4743, -3.5985, -5.2473, -3.2462, -3.5718, -4.7776,\n",
       "         -4.3747, -3.7981, -3.7365, -4.7261, -5.2473, -5.5929, -7.3457, -6.9017,\n",
       "         -3.2969, -3.0178, -5.0472, -5.1169, -3.3864, -3.5969, -3.7112, -7.1417,\n",
       "         -4.3407, -3.1914, -3.2236, -3.8362, -3.7725, -3.2207, -4.3931, -3.4903,\n",
       "         -5.5086, -3.2851, -4.3014, -3.0150, -6.3778, -3.9336, -5.5033, -4.2818,\n",
       "         -3.8376, -3.4193, -4.8189, -4.4110, -3.0109, -4.7062, -6.3714, -5.5088,\n",
       "         -3.3089, -3.5463, -3.3632, -3.3213, -3.0561, -4.8263, -4.1851, -4.0818,\n",
       "         -4.5296, -5.4598, -3.5688, -3.8677, -5.5530, -4.0895, -5.3818, -3.9292,\n",
       "         -3.6795, -4.4129, -3.5412, -3.0538, -5.0801, -3.4136, -2.9647, -4.0335,\n",
       "         -7.0182, -5.2399, -3.6924, -3.3045, -3.2860, -3.1140, -3.7551, -4.3398,\n",
       "         -3.6441, -3.5433, -3.0954, -3.8603, -3.0358, -3.8086, -3.4934, -3.8835,\n",
       "         -3.6569, -9.6160, -4.3333, -3.4845, -3.3981, -5.0105, -5.3584, -3.4514,\n",
       "         -3.1653, -4.7770, -5.0286, -3.6758, -4.5199, -4.6278, -3.6619, -3.3011,\n",
       "         -6.2241, -3.7888, -4.4836, -5.0239, -5.7023, -3.6766, -3.4767, -6.0759],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfm.sample(num_samples=2 ** 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d06e1b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfm.forward(torch.tensor([1.0,20.0],device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece56478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pgrad2/2448355h/.local/lib/python3.10/site-packages/normflows/flows/normalization.py:23: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  s_init = -torch.log(z.std(dim=self.batch_dims, keepdim=True) + 1e-6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf.NormalizingFlow(q0=q0, flows=flows, p=target).forward(torch.tensor([1.0,20.0],device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9ebd4b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2322888/1977296910.py:1: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(np.max(samples,axis=1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([inf, inf, inf, ..., inf, inf, inf])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.max(samples,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "46515370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2322888/1160389807.py:1: RuntimeWarning: overflow encountered in exp\n",
      "  np.log(np.exp(np.max(samples,axis=1)).mean())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.exp(np.max(samples,axis=1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7dc2e6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2028.5075, dtype=torch.float64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_U = torch.tensor(np.max(samples,axis=1) ) # shape: (batch_size,)\n",
    "\n",
    "# We want log( mean( exp(max_U) ) ) over the batch dimension\n",
    "log_E_exp_max_U = log_mean_exp(max_U, dim=0)\n",
    "log_E_exp_max_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "99638ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2322888/2814775696.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 2) Shift and exponentiate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshifted_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dim' is not defined"
     ]
    }
   ],
   "source": [
    "U_samples = f_U_model.sample((num_U_samples,))\n",
    "max_U = torch.max(U_samples, dim=1)[0]\n",
    "E_exp_max_U = torch.mean(torch.exp(max_U))\n",
    "\n",
    "max_U = torch.max(U_samples, dim=1)[0]\n",
    "\n",
    "# 2) Shift and exponentiate\n",
    "shifted_exp = torch.exp(x - x_max)\n",
    "\n",
    "# 3) Average, then take log\n",
    "mean_shifted_exp = torch.mean(shifted_exp, dim=dim, keepdim=True)\n",
    "log_mean_shifted_exp = torch.log(mean_shifted_exp)\n",
    "\n",
    "# 4) Add the max back\n",
    "out = x_max + log_mean_shifted_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05bbfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA RTX A6000 is available.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938e755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09f47233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "# a.pop()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9d0be2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, val=0, next=None):\n",
    "        self.val = val\n",
    "        self.next = next\n",
    "        \n",
    "node1 = Node(1)\n",
    "node2 = Node(2)\n",
    "node3 = Node(3)\n",
    "node4 = Node(4)\n",
    "node5 = Node(5)\n",
    "\n",
    "node1.next = node2\n",
    "node2.next = node3\n",
    "node3.next = node4\n",
    "node4.next = node5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc1d2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_odd = node1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "60f4d270",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'val'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2322715/2179818315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'val'"
     ]
    }
   ],
   "source": [
    "print(node4.next.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4a522f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_odd.next.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "47703f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oddEvenList(head):\n",
    "    \"\"\"\n",
    "    :type head: Optional[ListNode]\n",
    "    :rtype: Optional[ListNode]\n",
    "    \"\"\"\n",
    "    node_odd = head\n",
    "    node_oven = head.next\n",
    "    count = 1\n",
    "    while node_odd.next and node_odd.next.next:\n",
    "        node_odd.next = node_odd.next.next\n",
    "        node_odd = node_odd.next\n",
    "    while node_oven.next and node_oven.next.next:\n",
    "        print(node_oven.val)\n",
    "        print(node_oven.next.val)\n",
    "        print(node_oven.next.next.val)\n",
    "        node_oven.next = node_oven.next.next \n",
    "        if count == 1:\n",
    "             node_oven_start = node_oven\n",
    "        node_oven = node_oven.next\n",
    "        print(node_oven.val)\n",
    "        count += 1\n",
    "\n",
    "    node_oven.next = None\n",
    "    node_odd.next = node_oven_start\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9d984e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "5\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Node at 0x7fdb24298d30>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oddEvenList(node1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "31d38136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "head = node1\n",
    "count = 1\n",
    "while head and count<=10:\n",
    "    print(head.val)\n",
    "    head = head.next\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7437e8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example', 'good', 'a']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" example   good a\".split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
