{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d08095fb-9c58-477e-8c7c-b02a7e5e60fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvinecopulib as pv\n",
    "import numpy as np\n",
    "Gumble = pv.Bicop(pv.BicopFamily.gumbel, parameters=np.array([[1.5]]))\n",
    "cop = Gumble\n",
    "# Input: 2D array where each row is a pair [u, v]\n",
    "# points = np.array([[0.5, 0.5], [0.8, 0.9], [0.2, 0.3]])\n",
    "points = np.array([[0.5, 0.5],[0.5,0.5]])\n",
    "result = cop.cdf(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f7d2e4-d55b-4ebe-811d-3d0661819af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33277038, 0.33277038])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6c84f7-a96c-4697-8eb5-833ce5315bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(1, 100), torch.nn.Tanh(), torch.nn.Linear(100, 1))\n",
    "num_param = sum(p.numel() for p in model.parameters())\n",
    "names = list(n for n, _ in model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ccc3dd7-67d4-4dc6-838c-f1975c614ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.weight': Parameter containing:\n",
       " tensor([[-0.3226],\n",
       "         [-0.1051],\n",
       "         [ 0.0491],\n",
       "         [ 0.3574],\n",
       "         [ 0.2217],\n",
       "         [ 0.2377],\n",
       "         [ 0.9095],\n",
       "         [-0.6408],\n",
       "         [ 0.6124],\n",
       "         [ 0.5793],\n",
       "         [ 0.6193],\n",
       "         [-0.8654],\n",
       "         [ 0.3991],\n",
       "         [ 0.3176],\n",
       "         [-0.8946],\n",
       "         [ 0.2353],\n",
       "         [-0.7369],\n",
       "         [ 0.4547],\n",
       "         [-0.4555],\n",
       "         [ 0.5578],\n",
       "         [-0.6673],\n",
       "         [-0.2957],\n",
       "         [ 0.2049],\n",
       "         [-0.7798],\n",
       "         [ 0.2586],\n",
       "         [-0.5886],\n",
       "         [ 0.9430],\n",
       "         [-0.3897],\n",
       "         [-0.9949],\n",
       "         [-0.4149],\n",
       "         [ 0.1194],\n",
       "         [-0.7386],\n",
       "         [ 0.3991],\n",
       "         [-0.0709],\n",
       "         [-0.5558],\n",
       "         [ 0.2438],\n",
       "         [-0.6053],\n",
       "         [ 0.0823],\n",
       "         [-0.7684],\n",
       "         [-0.1965],\n",
       "         [-0.3536],\n",
       "         [-0.4826],\n",
       "         [ 0.0575],\n",
       "         [ 0.4861],\n",
       "         [-0.4327],\n",
       "         [ 0.9439],\n",
       "         [ 0.9541],\n",
       "         [-0.5006],\n",
       "         [ 0.1239],\n",
       "         [ 0.6606],\n",
       "         [ 0.6487],\n",
       "         [ 0.5012],\n",
       "         [-0.5305],\n",
       "         [-0.9699],\n",
       "         [ 0.8470],\n",
       "         [-0.3796],\n",
       "         [ 0.1354],\n",
       "         [-0.1891],\n",
       "         [-0.4371],\n",
       "         [-0.7103],\n",
       "         [ 0.1321],\n",
       "         [-0.8658],\n",
       "         [ 0.8271],\n",
       "         [ 0.2229],\n",
       "         [ 0.1343],\n",
       "         [-0.4062],\n",
       "         [ 0.2233],\n",
       "         [ 0.5906],\n",
       "         [-0.7112],\n",
       "         [ 0.6341],\n",
       "         [ 0.9025],\n",
       "         [ 0.6303],\n",
       "         [-0.8038],\n",
       "         [-0.1138],\n",
       "         [-0.3240],\n",
       "         [-0.8369],\n",
       "         [ 0.1412],\n",
       "         [-0.8685],\n",
       "         [ 0.0768],\n",
       "         [-0.5083],\n",
       "         [ 0.8830],\n",
       "         [-0.8053],\n",
       "         [ 0.0939],\n",
       "         [-0.4207],\n",
       "         [-0.7537],\n",
       "         [ 0.3775],\n",
       "         [-0.6843],\n",
       "         [ 0.8938],\n",
       "         [-0.0803],\n",
       "         [ 0.7518],\n",
       "         [-0.3940],\n",
       "         [-0.5282],\n",
       "         [ 0.2343],\n",
       "         [ 0.3597],\n",
       "         [ 0.0668],\n",
       "         [ 0.9022],\n",
       "         [-0.1366],\n",
       "         [-0.9152],\n",
       "         [ 0.7871],\n",
       "         [-0.7584]], requires_grad=True),\n",
       " '0.bias': Parameter containing:\n",
       " tensor([ 0.6523, -0.8206, -0.4333,  0.7069,  0.4151, -0.3759,  0.5743,  0.5752,\n",
       "         -0.7056,  0.8585,  0.1646, -0.0653,  0.6748, -0.5460,  0.2836, -0.7863,\n",
       "          0.7666, -0.5292,  0.7408, -0.1010,  0.3895,  0.8835, -0.6940, -0.5746,\n",
       "          0.4938,  0.0521,  0.3083, -0.0155,  0.7063, -0.5562,  0.0214,  0.7639,\n",
       "          0.7431, -0.8652,  0.7627,  0.6672,  0.7993,  0.4135, -0.0518, -0.4048,\n",
       "          0.9183, -0.2257,  0.7202,  0.3360,  0.4654,  0.2454, -0.6896,  0.7213,\n",
       "          0.9766, -0.8694,  0.0951,  0.1087, -0.1280,  0.2396, -0.2585, -0.3720,\n",
       "         -0.3022, -0.9361,  0.7278, -0.7747, -0.1331,  0.9035, -0.2383, -0.6978,\n",
       "         -0.7234, -0.1955,  0.6974, -0.0992,  0.5275, -0.8351,  0.7222,  0.9757,\n",
       "          0.7426,  0.2100, -0.4191, -0.9138,  0.1513, -0.2282,  0.7151,  0.9931,\n",
       "          0.4672, -0.0974, -0.5070,  0.9104, -0.7265,  0.6702, -0.2964, -0.2236,\n",
       "         -0.9917,  0.0617, -0.5380, -0.7774, -0.9814, -0.9222,  0.0425, -0.2844,\n",
       "          0.4875,  0.7123,  0.9471, -0.7285], requires_grad=True),\n",
       " '2.weight': Parameter containing:\n",
       " tensor([[ 0.0609, -0.0796, -0.0239, -0.0773, -0.0613,  0.0318,  0.0595, -0.0423,\n",
       "           0.0242,  0.0620, -0.0506, -0.0561, -0.0945,  0.0410,  0.0427,  0.0102,\n",
       "          -0.0223,  0.0089,  0.0049, -0.0620,  0.0018,  0.0406, -0.0714,  0.0674,\n",
       "           0.0480,  0.0345, -0.0670, -0.0788,  0.0796,  0.0056,  0.0086, -0.0514,\n",
       "           0.0305, -0.0262, -0.0595,  0.0436,  0.0117, -0.0960, -0.0873, -0.0880,\n",
       "           0.0004, -0.0997, -0.0666, -0.0600, -0.0687,  0.0571, -0.0667,  0.0686,\n",
       "          -0.0042, -0.0149, -0.0706,  0.0160,  0.0634, -0.0809,  0.0897, -0.0107,\n",
       "           0.0661,  0.0110, -0.0975, -0.0457, -0.0140,  0.0902,  0.0523,  0.0655,\n",
       "           0.0299,  0.0729,  0.0177,  0.0944,  0.0110,  0.0211, -0.0429, -0.0806,\n",
       "          -0.0711, -0.0232,  0.0370, -0.0970, -0.0944,  0.0430,  0.0967, -0.0200,\n",
       "          -0.0440,  0.0419,  0.0261,  0.0281,  0.0906,  0.0092, -0.0285,  0.0197,\n",
       "           0.0133, -0.0850, -0.0630, -0.0227,  0.0728, -0.0150, -0.0790, -0.0366,\n",
       "          -0.0356,  0.0127,  0.0839,  0.0862]], requires_grad=True),\n",
       " '2.bias': Parameter containing:\n",
       " tensor([0.0306], requires_grad=True)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{n: p for n, p in zip(names, tuple(model.parameters()))}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
